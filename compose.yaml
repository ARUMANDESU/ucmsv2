services:
    postgresql:
        container_name: ucmsv2-postgresql
        image: "postgres:${PG_VERSION:-17-alpine}"
        ports:
            - 8765:5432
        environment:
            POSTGRES_DB: "ucms"
            POSTGRES_USER: "user"
            POSTGRES_PASSWORD: "password"
        volumes:
            - postgresql_data:/var/lib/postgresql/data
        networks:
            - default
        restart: always
        profiles: [ "infra", "storage" ]
        healthcheck:
            test: [ "CMD-SHELL", "pg_isready -U user -d ucms" ]
            interval: 30s
            timeout: 10s
            retries: 5

    minio-s3:
        container_name: ucmsv2-minio
        image: "minio/minio:${MINIO_VERSION:-latest}"
        command: server /data --console-address ":9001"
        ports:
            - 9000:9000
            - 9001:9001
        environment:
            MINIO_ROOT_USER: "ucmsadmin"
            MINIO_ROOT_PASSWORD: "ucmsadminpass"
        volumes:
            - minio_data:/data
        networks:
            - default
        restart: always
        profiles: [ "infra", "storage" ]
        healthcheck:
            test: [ "CMD-SHELL", "curl -f http://localhost:9000/minio/health/live || exit 1" ]
            interval: 30s
            timeout: 10s
            retries: 5

    otel-collector:
        container_name: ucmsv2-otel-collector
        image: "otel/opentelemetry-collector-contrib:${OTEL_VERSION:-latest}"
        command: [ "--config=/etc/otel-collector-config.yaml" ]
        volumes:
            - ./config/otel-collector.yaml:/etc/otel-collector-config.yaml
        ports:
            - 1888:1888 # pprof extension
            - 8888:8888 # Prometheus metrics exposed by the Collector
            - 8889:8889 # Prometheus exporter metrics
            - 13133:13133 # health_check extension
            - 4317:4317 # OTLP gRPC receiver
            - 4318:4318 # OTLP HTTP receiver
            - 55679:55679 # zpages extension
        depends_on:
            prometheus:
                condition: service_healthy
            loki:
                condition: service_healthy
            tempo:
                condition: service_healthy
        networks:
            - default
        restart: always
        profiles: [ "infra" ]
        healthcheck:
            test: ["CMD", "curl", "-f", "http://localhost:13133/health"]
            interval: 30s
            timeout: 10s
            retries: 5

    grafana:
        container_name: ucmsv2-grafana
        image: "grafana/grafana:${GRAFANA_VERSION:-latest}"
        ports:
            - 3000:3000
        environment:
            GF_SECURITY_ADMIN_USER: "admin"
            GF_SECURITY_ADMIN_PASSWORD: "adminpass"
        volumes:
            - grafana_data:/var/lib/grafana
            - ./config/grafana:/etc/grafana/config
            - ./config/grafana/provisioning/datasources/datasources.yaml:/etc/grafana/provisioning/datasources/datasources.yaml
            - ./config/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards
        depends_on:
            prometheus:
                condition: service_healthy
            loki:
                condition: service_healthy
            tempo:
                condition: service_healthy
        networks:
            - default
        restart: always
        profiles: [ "infra" ]
        healthcheck:
            test: [ "CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1" ]
            interval: 30s
            timeout: 10s
            retries: 5

    loki:
        container_name: ucmsv2-loki
        image: "grafana/loki:${LOKI_VERSION:-latest}"
        command: -config.file=/etc/loki/local-config.yaml
        ports:
            - 3100:3100
        volumes:
            - loki_data:/loki
            - ./config/loki.yaml:/etc/loki/local-config.yaml
        networks:
            - default
        restart: always
        profiles: [ "infra" ]
        healthcheck:
            test: [ "CMD", "wget", "--spider", "-q", "http://localhost:3100/ready" ]
            interval: 30s
            timeout: 5s
            retries: 5

    tempo:
        container_name: ucmsv2-tempo
        image: "grafana/tempo:${TEMPO_VERSION:-latest}"
        command: [ "-config.file=/etc/tempo/config.yaml" ]
        ports:
            - 14268 # jaeger ingest
            - 3200 # tempo
            - 4317 # otlp grpc
            - 4318 # otlp http
            - 9411 # zipkin
        volumes:
            - tempo_data:/var/tempo
            - ./config/tempo.yaml:/etc/tempo/config.yaml
        networks:
            - default
        restart: always
        profiles: [ "infra" ]
        healthcheck:
            test: [ "CMD", "wget", "--spider", "-q", "http://localhost:3200/ready" ]
            interval: 30s
            timeout: 5s
            retries: 5

    prometheus:
        container_name: ucmsv2-prometheus
        image: "prom/prometheus:${PROMETHEUS_VERSION:-latest}"
        ports:
            - 9090:9090
        volumes:
            - ./config/prometheus.yaml:/etc/prometheus/prometheus.yml
        networks:
            - default
        restart: always
        profiles: [ "infra" ]
        healthcheck:
            test: [ "CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy" ]
            interval: 30s
            timeout: 10s
            retries: 5

volumes:
    postgresql_data:
    minio_data:
    grafana_data:
    loki_data:
    tempo_data:


networks:
    default:
        name: ucmsv2_default
        driver: bridge
